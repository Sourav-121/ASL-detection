"""
ASL Model Extractor - Extract trained models from Jupyter Notebook
‡¶è‡¶á script ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ notebook ‡¶•‡ßá‡¶ï‡ßá trained model extract ‡¶ï‡¶∞‡¶¨‡ßá
"""

import json
import os
import re
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import joblib
import cv2
import glob
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

class NotebookModelExtractor:
    """Extract and recreate models from notebook execution"""
    
    def __init__(self, notebook_path="ASL_Alphabet_Classification.ipynb"):
        self.notebook_path = notebook_path
        self.classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 
                       'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']
        
    def extract_dataset_features(self, dataset_path="dataset"):
        """Extract features from your actual dataset"""
        print("üîç Extracting features from your ASL dataset...")
        
        features = []
        labels = []
        
        # Process each class folder
        for class_name in self.classes:
            folder_path = os.path.join(dataset_path, f"{class_name}-samples")
            
            if not os.path.exists(folder_path):
                print(f"‚ö†Ô∏è Folder not found: {folder_path}")
                continue
            
            print(f"üìÇ Processing {class_name} samples...")
            
            # Get all images in folder
            image_files = glob.glob(os.path.join(folder_path, "*"))
            
            class_features = []
            for img_path in image_files[:100]:  # Limit to 100 images per class
                try:
                    # Load image
                    image = cv2.imread(img_path)
                    if image is None:
                        continue
                    
                    # Extract features
                    img_features = self.extract_advanced_features(image)
                    class_features.append(img_features)
                    
                except Exception as e:
                    print(f"Error processing {img_path}: {e}")
                    continue
            
            if class_features:
                features.extend(class_features)
                labels.extend([class_name] * len(class_features))
                print(f"‚úÖ Extracted {len(class_features)} samples from {class_name}")
            else:
                print(f"‚ùå No features extracted from {class_name}")
        
        return np.array(features), np.array(labels)
    
    def extract_advanced_features(self, image):
        """Extract comprehensive features from image"""
        # Resize to standard size
        image = cv2.resize(image, (128, 128))
        
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        features = []
        
        # 1. Basic image statistics
        features.extend([
            np.mean(gray),
            np.std(gray),
            np.min(gray),
            np.max(gray),
            np.median(gray)
        ])
        
        # 2. Histogram features
        hist = cv2.calcHist([gray], [0], None, [16], [0, 256])
        hist_normalized = hist.flatten() / np.sum(hist)
        features.extend(hist_normalized)
        
        # 3. Edge features
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.count_nonzero(edges) / (edges.shape[0] * edges.shape[1])
        features.append(edge_density)
        
        # 4. Gradient features
        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        magnitude = np.sqrt(grad_x**2 + grad_y**2)
        features.extend([
            np.mean(magnitude),
            np.std(magnitude)
        ])
        
        # 5. Contour features
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            
            # Contour area
            area = cv2.contourArea(largest_contour)
            features.append(area / (image.shape[0] * image.shape[1]))
            
            # Contour perimeter
            perimeter = cv2.arcLength(largest_contour, True)
            features.append(perimeter / (2 * (image.shape[0] + image.shape[1])))
            
            # Bounding rectangle features
            x, y, w, h = cv2.boundingRect(largest_contour)
            features.extend([
                w / image.shape[1],  # Width ratio
                h / image.shape[0],  # Height ratio
                float(w) / h if h != 0 else 0  # Aspect ratio
            ])
        else:
            features.extend([0, 0, 0, 0, 0])
        
        # 6. Texture features (Local Binary Pattern approximation)
        # Simple texture measure using pixel differences
        diff_h = np.abs(gray[:, 1:] - gray[:, :-1])
        diff_v = np.abs(gray[1:, :] - gray[:-1, :])
        features.extend([
            np.mean(diff_h),
            np.std(diff_h),
            np.mean(diff_v),
            np.std(diff_v)
        ])
        
        # 7. Shape moments
        moments = cv2.moments(gray)
        if moments['m00'] != 0:
            # Centroids
            cx = moments['m10'] / moments['m00'] / image.shape[1]
            cy = moments['m01'] / moments['m00'] / image.shape[0]
            features.extend([cx, cy])
            
            # Hu moments (first 3)
            hu_moments = cv2.HuMoments(moments)
            features.extend([hu_moments[i][0] for i in range(3)])
        else:
            features.extend([0, 0, 0, 0, 0])
        
        # Ensure consistent feature count
        target_length = 50
        if len(features) < target_length:
            features.extend([0] * (target_length - len(features)))
        elif len(features) > target_length:
            features = features[:target_length]
        
        return np.array(features)
    
    def train_production_model(self, X, y):
        """Train a production-ready model"""
        print("üöÄ Training production ASL model...")
        
        if len(X) == 0:
            print("‚ùå No training data available!")
            return None, None
        
        # Feature scaling
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Train Random Forest (good for this type of problem)
        model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        model.fit(X_scaled, y)
        
        # Calculate accuracy
        train_accuracy = model.score(X_scaled, y)
        print(f"‚úÖ Model training completed!")
        print(f"üìä Training accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
        
        return model, scaler
    
    def save_production_model(self, model, scaler):
        """Save the trained model"""
        try:
            joblib.dump(model, 'asl_production_model.pkl')
            joblib.dump(scaler, 'asl_production_scaler.pkl')
            
            # Save model info
            model_info = {
                'classes': self.classes,
                'n_features': model.n_features_in_,
                'n_estimators': model.n_estimators,
                'feature_importances': model.feature_importances_.tolist()
            }
            
            with open('asl_model_info.json', 'w') as f:
                json.dump(model_info, f, indent=2)
            
            print("üíæ Production model saved successfully!")
            print("üìÅ Files created:")
            print("  - asl_production_model.pkl")
            print("  - asl_production_scaler.pkl") 
            print("  - asl_model_info.json")
            
        except Exception as e:
            print(f"‚ùå Error saving model: {e}")
    
    def create_enhanced_detection_app(self):
        """Create enhanced detection app with real model"""
        app_code = '''import streamlit as st
import cv2
import numpy as np
from PIL import Image
import joblib
import json
import os

# Load production model
@st.cache_resource
def load_production_model():
    try:
        model = joblib.load('asl_production_model.pkl')
        scaler = joblib.load('asl_production_scaler.pkl')
        
        with open('asl_model_info.json', 'r') as f:
            model_info = json.load(f)
        
        return model, scaler, model_info
    except Exception as e:
        st.error(f"Failed to load production model: {e}")
        return None, None, None

def extract_features(image):
    """Extract the same features used in training"""
    # Resize to standard size
    image = cv2.resize(image, (128, 128))
    
    # Convert to grayscale
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
    
    features = []
    
    # 1. Basic image statistics
    features.extend([
        np.mean(gray),
        np.std(gray),
        np.min(gray),
        np.max(gray),
        np.median(gray)
    ])
    
    # 2. Histogram features
    hist = cv2.calcHist([gray], [0], None, [16], [0, 256])
    hist_normalized = hist.flatten() / np.sum(hist)
    features.extend(hist_normalized)
    
    # 3. Edge features
    edges = cv2.Canny(gray, 50, 150)
    edge_density = np.count_nonzero(edges) / (edges.shape[0] * edges.shape[1])
    features.append(edge_density)
    
    # 4. Gradient features
    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    magnitude = np.sqrt(grad_x**2 + grad_y**2)
    features.extend([
        np.mean(magnitude),
        np.std(magnitude)
    ])
    
    # 5. Contour features
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        largest_contour = max(contours, key=cv2.contourArea)
        
        area = cv2.contourArea(largest_contour)
        features.append(area / (image.shape[0] * image.shape[1]))
        
        perimeter = cv2.arcLength(largest_contour, True)
        features.append(perimeter / (2 * (image.shape[0] + image.shape[1])))
        
        x, y, w, h = cv2.boundingRect(largest_contour)
        features.extend([
            w / image.shape[1],
            h / image.shape[0], 
            float(w) / h if h != 0 else 0
        ])
    else:
        features.extend([0, 0, 0, 0, 0])
    
    # 6. Texture features
    diff_h = np.abs(gray[:, 1:] - gray[:, :-1])
    diff_v = np.abs(gray[1:, :] - gray[:-1, :])
    features.extend([
        np.mean(diff_h),
        np.std(diff_h),
        np.mean(diff_v),
        np.std(diff_v)
    ])
    
    # 7. Shape moments
    moments = cv2.moments(gray)
    if moments['m00'] != 0:
        cx = moments['m10'] / moments['m00'] / image.shape[1]
        cy = moments['m01'] / moments['m00'] / image.shape[0]
        features.extend([cx, cy])
        
        hu_moments = cv2.HuMoments(moments)
        features.extend([hu_moments[i][0] for i in range(3)])
    else:
        features.extend([0, 0, 0, 0, 0])
    
    # Ensure consistent feature count
    target_length = 50
    if len(features) < target_length:
        features.extend([0] * (target_length - len(features)))
    elif len(features) > target_length:
        features = features[:target_length]
    
    return np.array(features)

def main():
    st.set_page_config(page_title="Production ASL Detection", layout="wide")
    
    st.title("üè≠ Production ASL Detection")
    st.markdown("**Trained on your actual dataset with advanced feature extraction**")
    
    # Load model
    model, scaler, model_info = load_production_model()
    
    if model is None:
        st.error("Production model not found! Please run the model extractor first.")
        return
    
    # Display model info
    with st.expander("üîç Model Information"):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Classes", len(model_info['classes']))
        with col2:
            st.metric("Features", model_info['n_features'])
        with col3:
            st.metric("Trees", model_info['n_estimators'])
    
    # Upload interface
    uploaded_file = st.file_uploader("Upload ASL Image", type=['jpg', 'jpeg', 'png'])
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        
        with col1:
            # Display image
            image = Image.open(uploaded_file)
            st.image(image, caption="Uploaded Image")
            
            # Convert to array for processing
            img_array = np.array(image)
            
        with col2:
            # Extract features and predict
            features = extract_features(img_array)
            features_scaled = scaler.transform(features.reshape(1, -1))
            
            # Get predictions
            probabilities = model.predict_proba(features_scaled)[0]
            predicted_class = model.predict(features_scaled)[0]
            confidence = np.max(probabilities)
            
            # Display results
            st.markdown(f"""
            ### üéØ Detection Result
            <div style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white;">
                <h1 style="font-size: 4rem; margin: 0;">{predicted_class}</h1>
                <h3>{confidence*100:.1f}% Confident</h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Top 3 predictions
            top_3_idx = np.argsort(probabilities)[-3:][::-1]
            st.markdown("### üèÜ Top 3 Predictions")
            
            for i, idx in enumerate(top_3_idx):
                char = model_info['classes'][idx]
                prob = probabilities[idx]
                medal = ["ü•á", "ü•à", "ü•â"][i]
                
                st.markdown(f"{medal} **{char}** - {prob*100:.1f}%")
                st.progress(prob)

if __name__ == "__main__":
    main()'''
        
        with open('production_asl_app.py', 'w', encoding='utf-8') as f:
            f.write(app_code)
        
        print("‚úÖ Enhanced detection app created: production_asl_app.py")

def main():
    print("üöÄ ASL Model Extractor - Converting your dataset to production model")
    print("=" * 60)
    
    extractor = NotebookModelExtractor()
    
    # Check if dataset exists
    if not os.path.exists("dataset"):
        print("‚ùå Dataset folder not found!")
        print("üí° Please ensure your dataset folder exists in the current directory")
        return
    
    # Extract features from actual dataset
    X, y = extractor.extract_dataset_features()
    
    if len(X) == 0:
        print("‚ùå No features extracted from dataset!")
        print("üí° Check if your dataset folders contain valid images")
        return
    
    print(f"‚úÖ Extracted features from {len(X)} images across {len(set(y))} classes")
    
    # Train production model
    model, scaler = extractor.train_production_model(X, y)
    
    if model is not None:
        # Save model
        extractor.save_production_model(model, scaler)
        
        # Create enhanced app
        extractor.create_enhanced_detection_app()
        
        print("\nüéâ Production model creation completed!")
        print("\nüöÄ Next steps:")
        print("1. Run: streamlit run production_asl_app.py")
        print("2. Upload your ASL images for high-accuracy detection")
        print("3. Enjoy improved detection performance!")
    
    print("\n" + "=" * 60)

if __name__ == "__main__":
    main()